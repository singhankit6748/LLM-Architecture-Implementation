{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94d23e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 439478\n",
      "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he d\n"
     ]
    }
   ],
   "source": [
    "with open(\"01 Harry Potter and the Sorcerers Stone.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52192fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the 439478 character short story into individual words and special character.\n",
    "# we have to import re for text regular expression operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec43bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)',text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1fa4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)',text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e572329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9316116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'World', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, World.Is this-- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)' ,text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38d0c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'r', '.', 'and', 'Mrs', '.', 'Dursley', ',', 'of', 'number', 'four', ',', 'Privet', 'Drive', ',', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', ',', 'thank', 'you', 'very', 'much', '.', 'They', 'were', 'the', 'last', 'people', 'you’d', 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', ',', 'because', 'they', 'just', 'didn’t', 'hold', 'with', 'such', 'nonsense', '.', 'Mr', '.', 'Dursley', 'was', 'the', 'director', 'of', 'a', 'firm', 'called', 'Grunnings', ',', 'which', 'made', 'drills', '.', 'He', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.', 'Mrs', '.', 'Dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', ',', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', ',', 'spying', 'on', 'the', 'neighbors', '.', 'The', 'Dursleys', 'had', 'a', 'small', 'son', 'called', 'Dudley', 'and', 'in', 'their', 'opinion', 'there', 'was', 'no', 'finer', 'boy', 'anywhere', '.', 'The', 'Dursleys', 'had', 'everything', 'they', 'wanted', ',', 'but', 'they', 'also', 'had', 'a', 'secret', ',', 'and', 'their', 'greatest', 'fear', 'was', 'that', 'somebody', 'would', 'discover', 'it', '.', 'They', 'didn’t', 'think', 'they', 'could', 'bear', 'it', 'if', 'anyone', 'found', 'out', 'about', 'the', 'Potters', '.', 'Mrs', '.', 'Potter', 'was', 'Mrs', '.', 'Dursley’s', 'sister', ',', 'but', 'they', 'hadn’t', 'met', 'for', 'several', 'years', ';', 'in', 'fact', ',', 'Mrs', '.', 'Dursley', 'pretended', 'she', 'didn’t', 'have', 'a', 'sister', ',', 'because', 'her', 'sister', 'and', 'her', 'good-for-nothing', 'husband', 'were', 'as', 'unDursleyish', 'as', 'it', 'was', 'possible', 'to', 'be', '.', 'The', 'Dursleys', 'shuddered', 'to', 'think', 'what', 'the', 'neighbors', 'would', 'say', 'if', 'the', 'Potters', 'arrived', 'in', 'the', 'street', '.', 'The', 'Dursleys', 'knew', 'that', 'the', 'Potters', 'had', 'a', 'small', 'son', ',', 'too', ',', 'but', 'they', 'had', 'never', 'even', 'seen', 'him', '.', 'This', 'boy', 'was', 'another', 'good', 'reason', 'for', 'keeping', 'the', 'Potters', 'away', ';', 'they', 'didn’t', 'want', 'Dudley', 'mixing', 'with', 'a', 'child', 'like', 'that', '.', 'When', 'Mr', '.', 'and', 'Mrs', '.', 'Dursley', 'woke', 'up', 'on', 'the', 'dull', ',', 'gray', 'Tuesday', 'our', 'story', 'starts', ',', 'there', 'was', 'nothing', 'about', 'the', 'cloudy', 'sky', 'outside', 'to', 'suggest', 'that', 'strange', 'and', 'mysterious', 'things', 'would', 'soon', 'be', 'happening', 'all', 'over', 'the', 'country', '.', 'Mr', '.', 'Dursley', 'hummed', 'as', 'he', 'picked', 'out', 'his', 'most', 'boring', 'tie', 'for', 'work', ',', 'and', 'Mrs', '.', 'Dursley', 'gossiped', 'away', 'happily', 'as', 'she', 'wrestled', 'a', 'screaming', 'Dudley', 'into', 'his', 'high', 'chair', '.', 'None', 'of', 'them', 'noticed', 'a', 'large', ',', 'tawny', 'owl', 'flutter', 'past', 'the', 'window', '.', 'At', 'half', 'past', 'eight', ',', 'Mr', '.', 'Dursley', 'picked', 'up', 'his', 'briefcase', ',', 'pecked', 'Mrs', '.', 'Dursley', 'on', 'the', 'cheek', ',', 'and', 'tried', 'to', 'kiss', 'Dudley', 'good-bye', 'but', 'missed', ',', 'because', 'Dudley', 'was', 'now', 'having', 'a', 'tantrum', 'and', 'throwing', 'his', 'cereal', 'at', 'the', 'walls', '.', '“Little', 'tyke', ',', '”', 'chortled', 'Mr', '.', 'Dursley', 'as', 'he', 'left', 'the', 'house', '.', 'He', 'got', 'into', 'his', 'car', 'and', 'backed', 'out', 'of', 'number', 'four’s', 'drive', '.', 'It', 'was', 'on', 'the', 'corner', 'of', 'the', 'street', 'that', 'he', 'noticed', 'the', 'first', 'sign', 'of', 'something', 'peculiar', '—', 'a', 'cat', 'reading', 'a', 'map', '.', 'For', 'a', 'second', ',', 'Mr', '.', 'Dursley', 'didn’t', 'realize', 'what', 'he', 'had', 'seen', '—']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b880995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93318\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec3b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7572\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocal_size = len(all_words)\n",
    "print(vocal_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ffdeb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer, token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6db4caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "(\"'\", 1)\n",
      "('(', 2)\n",
      "(')', 3)\n",
      "('*', 4)\n",
      "(',', 5)\n",
      "('-', 6)\n",
      "('-bodied', 7)\n",
      "('.', 8)\n",
      "('1', 9)\n",
      "('1473', 10)\n",
      "('1637', 11)\n",
      "('17', 12)\n",
      "('1709', 13)\n",
      "('1945', 14)\n",
      "('2', 15)\n",
      "('3', 16)\n",
      "('31', 17)\n",
      "('382', 18)\n",
      "('4', 19)\n",
      "(':', 20)\n",
      "(';', 21)\n",
      "('?', 22)\n",
      "('A', 23)\n",
      "('ALBUS', 24)\n",
      "('ALLEY', 25)\n",
      "('ALLOWED', 26)\n",
      "('AM', 27)\n",
      "('AND', 28)\n",
      "('ANYTHING', 29)\n",
      "('ARE', 30)\n",
      "('AT', 31)\n",
      "('About', 32)\n",
      "('According', 33)\n",
      "('Adalbert', 34)\n",
      "('Add', 35)\n",
      "('Adrian', 36)\n",
      "('Africa', 37)\n",
      "('African', 38)\n",
      "('After', 39)\n",
      "('Against', 40)\n",
      "('Ages', 41)\n",
      "('Agrippa', 42)\n",
      "('Ah', 43)\n",
      "('Ahead', 44)\n",
      "('Alberic', 45)\n",
      "('Albus', 46)\n",
      "('Albus…”', 47)\n",
      "('Algie', 48)\n",
      "('Alicia', 49)\n",
      "('All', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a166604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03eda057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[735, 8, 292, 6597, 6131, 2531, 4452, 1300, 2991, 1954, 472, 5]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"Mr. Dursley was the director of a firm called Grunnings,\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e56769e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Dursley was the director of a firm called Grunnings,'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d60d703",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, do you like tea?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mencode(text))\n",
      "Cell \u001b[1;32mIn[39], line 12\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      7\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.:;?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m      9\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     11\u001b[0m ]\n\u001b[1;32m---> 12\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "text = \"Hello, do you like tea?\"\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df885d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86e097aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7574"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cde82af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('…Oak', 7569)\n",
      "('…Then', 7570)\n",
      "('…”', 7571)\n",
      "('<|endoftext|>', 7572)\n",
      "('<|unk|>', 7573)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56105dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "452492de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fa87fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7573,\n",
       " 5,\n",
       " 2569,\n",
       " 6871,\n",
       " 3983,\n",
       " 6074,\n",
       " 22,\n",
       " 7572,\n",
       " 583,\n",
       " 6131,\n",
       " 7573,\n",
       " 7573,\n",
       " 4452,\n",
       " 6131,\n",
       " 4565,\n",
       " 8]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2861878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the <|unk|> <|unk|> of the palace.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784dbe15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312449f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07892a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f8b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e5a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77289dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
